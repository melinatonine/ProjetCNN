{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to investigate the performance of spike interface in localizing neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_675765/4027547306.py:15: DeprecationWarning: Please use `gaussian_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter1d\n"
     ]
    }
   ],
   "source": [
    "import MEArec as mr # what we will use to create a synthetic recording\n",
    "import spikeinterface.full as si  # what we will use to sort the spikes\n",
    "\n",
    "# Other useful imports \n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import numpy as np\n",
    "import yaml\n",
    "import warnings\n",
    "from probeinterface.plotting import plot_probe\n",
    "from matplotlib import cm\n",
    "from probeinterface import read_prb\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from os import listdir\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "import spikeinterface.widgets as sw\n",
    "import time\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.legend_handler import HandlerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_folder = \"C:\\\\Users\\\\melin\\\\Anaconda3\\\\envs\\\\si_env\\\\Lib\\\\site-packages\\\\MEArec\\\\cell_models\\\\bbp\" # folder where we downloaded some cell models (13)\n",
    "working_folder = \"C:\\\\Users\\\\melin\\\\Desktop\\\\COURS_M2_CNN\\\\Projet\\\\\" # the current folder \n",
    "param_folder = working_folder + 'params_locations\\\\' # where we put they yaml files with all the parameters\n",
    "files_folder = working_folder + 'temporary_files_locations\\\\' # where we want to put the created files \n",
    "param_ext = '.yml' # yaml files contain dictionaries for our parameters \n",
    "files_ext = \".h5\" # h5 files are created to save what we do \n",
    "parallel_compute = 4 # number of parallel processing that will be ongoing for heavy process \n",
    "templates_file = working_folder + 'data_real\\\\templates\\\\full_templates.npy'\n",
    "\n",
    "maps = 'Blues', 'Purples'\n",
    "cmaps = cm.get_cmap(maps[0]), cm.get_cmap(maps[1])\n",
    "colors_binary = cmaps[0](0.7), cmaps[1](0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data with MEArec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\melin\\\\Desktop\\\\COURS_M2_CNN\\\\Projet\\\\params_locations\\\\templates.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFake_probe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m'\u001b[39m :{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobe\u001b[39m\u001b[38;5;124m'\u001b[39m : probe} , \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspiketrains\u001b[39m\u001b[38;5;124m'\u001b[39m : {},\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecordings\u001b[39m\u001b[38;5;124m'\u001b[39m : {}\n\u001b[1;32m     26\u001b[0m }\n\u001b[0;32m---> 28\u001b[0m params \u001b[38;5;241m=\u001b[39m parameters_modification(param_folder, parameters)\n",
      "Cell \u001b[0;32mIn [3], line 9\u001b[0m, in \u001b[0;36mparameters_modification\u001b[0;34m(param_folder, parameters)\u001b[0m\n\u001b[1;32m      6\u001b[0m new_parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(parameters\u001b[38;5;241m.\u001b[39mkeys()) : \n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam_folder\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mparam_ext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m             new_parameters[param] \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\melin\\\\Desktop\\\\COURS_M2_CNN\\\\Projet\\\\params_locations\\\\templates.yml'"
     ]
    }
   ],
   "source": [
    "def parameters_modification(param_folder, parameters) : \n",
    "    '''\n",
    "    This function reads yaml files with the parameters for generating MEA templates, spiketrains and recordings \n",
    "    and can change the parameters defined in the dictionnary parameters\n",
    "    '''\n",
    "    new_parameters = {\n",
    "    }\n",
    "    for param in list(parameters.keys()) : \n",
    "        with open(param_folder+param+param_ext) as file:\n",
    "            try:\n",
    "                new_parameters[param] = yaml.safe_load(file)\n",
    "                for elt in parameters[param] :\n",
    "                    if elt in new_parameters[param] :\n",
    "                        new_parameters[param][elt] = parameters[param][elt] \n",
    "                    else :\n",
    "                        print('parameter not found')\n",
    "            except yaml.YAMLError as exception:\n",
    "                print(exception)\n",
    "    return (new_parameters)\n",
    "\n",
    "probe = 'Fake_probe'\n",
    "parameters = {\n",
    "    'templates' :{'probe' : probe} , \n",
    "    'spiketrains' : {},\n",
    "    'recordings' : {}\n",
    "}\n",
    "\n",
    "params = parameters_modification(param_folder, parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate artifical data with parameters defined in a yaml file. Templates and recording files are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_data(params, files_folder, probe) : \n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") # There are a lot of deprecation warnings that make the ouput not very easy to read, so we ignore them for now \n",
    "\n",
    "        # Generation of templates, spiketrains and recordings with MEArec\n",
    "        tempgen = mr.gen_templates(cell_models_folder=cell_folder, params=params['templates'], n_jobs=parallel_compute, verbose=False)\n",
    "        spgen = mr.gen_spiketrains(params=params['spiketrains'], verbose=False)\n",
    "        recgen = mr.gen_recordings(params=params['recordings'], spgen = spgen, tempgen=tempgen, n_jobs=parallel_compute, verbose=False)\n",
    "\n",
    "        #  Saving in the output folder 'files_folder' \n",
    "        mr.save_template_generator(tempgen, filename=f\"{files_folder}templates{probe}{files_ext}\", verbose = False)\n",
    "        mr.save_recording_generator(recgen, filename=f\"{files_folder}recordings{probe}{files_ext}\", verbose=False)\n",
    "\n",
    "\n",
    "time_gener = time.time()\n",
    "generating_data(params, files_folder, probe)\n",
    "time_gener = time.time - time_gener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class artificial_data:\n",
    "\n",
    "    def __init__(self, files_folder, probe) :\n",
    "        self.probe = probe\n",
    "        self.folder = files_folder\n",
    "        self.tempgen = mr.load_templates(f\"{files_folder}templates{probe}{files_ext}\")\n",
    "        self.templates = self.tempgen.templates\n",
    "        self.recgen = mr.load_recordings(f\"{files_folder}recordings{probe}{files_ext}\")\n",
    "        self.templates_in_recording()\n",
    "\n",
    "    def load_in_spike_interface(self) :\n",
    "        self.recording_si, self.sorting_si = si.read_mearec(f\"{self.folder}recordings{self.probe}{files_ext}\")\n",
    "\n",
    "    def templates_in_recording (self) :\n",
    "        '''\n",
    "        Not all the templates created are used in the recording\n",
    "        We list in 'self.template_ids' the identification numbers of the templates of interest\n",
    "        '''\n",
    "        self.template_ids = self.recgen.template_ids\n",
    "        self.n_templates = len(self.template_ids)\n",
    "        self.n_probes = len(self.tempgen.templates[0])\n",
    "\n",
    "    def predicted_locations (self, method = 'monopolar_triangulation', ms_before=1., ms_after=1.5, radius_um=50, max_distance_um=1000) :\n",
    "        '''\n",
    "        Extract waveforms for each template of interest\n",
    "        And compute the location with the method selected, default is monopolar_triangulation\n",
    "        '''\n",
    "        self.locations_pred =  [0]*self.n_templates\n",
    "        self.unit_pred = [0]*self.n_templates\n",
    "        for num in range (self.n_templates) :\n",
    "            sorting_num = self.sorting_si.select_units([f\"#{num}\"]) \n",
    "            wv_num = si.extract_waveforms(recording = self.recording_si, sorting= sorting_num, overwrite= False, folder=f\"{self.folder}//waveforms//wv_{self.probe}_{num}\", load_if_exists=True, max_spikes_per_unit=None)\n",
    "            if method == 'monopolar_triangulation':\n",
    "                self.locations_pred[num]  = si.compute_spike_locations(wv_num, method = method, ms_before=ms_before, ms_after= ms_after) \n",
    "                self.unit_pred[num] = si.compute_unit_locations(wv_num, method = method, radius_um=radius_um, max_distance_um=max_distance_um)\n",
    "            else :\n",
    "                self.locations_pred[num]  = si.compute_spike_locations(wv_num, method = method) \n",
    "                self.unit_pred[num] = si.compute_unit_locations(wv_num, method = method)\n",
    "\n",
    "    def find_errors(self) :\n",
    "        '''\n",
    "        We get the real positions of the templates of interest and compare them with the predictions made by spike interface \n",
    "        '''\n",
    "        self.locations_real = [self.tempgen.locations[template] for template in self.template_ids]\n",
    "        self.pred_errors = [0]*self.n_templates\n",
    "        self.unit_errors = [0]*self.n_templates\n",
    "        for template in range (self.n_templates) :\n",
    "            self.pred_errors[template] = [0]*len(self.locations_pred[template])\n",
    "            xyzreal = (self.locations_real[template][1], self.locations_real[template][2], self.locations_real[template][0])\n",
    "            for time in range (len(self.locations_pred[template])) :\n",
    "                if len(self.locations_pred[template][time]) < 3 :\n",
    "                    xyzpred = (self.locations_pred[template][time][0], self.locations_pred[template][time][1],0)\n",
    "                    self.pred_errors[template][time] = math.dist(xyzreal, xyzpred)\n",
    "                else:\n",
    "                    xyzpred_1 = (self.locations_pred[template][time][0], self.locations_pred[template][time][1], self.locations_pred[template][time][2])\n",
    "                    xyzpred_2 = (self.locations_pred[template][time][0], self.locations_pred[template][time][1], self.locations_pred[template][time][2])\n",
    "                    self.pred_errors[template][time] = min(math.dist(xyzreal, xyzpred_1),math.dist(xyzreal, xyzpred_2))\n",
    "            if len(self.locations_pred[template][time]) < 3 :\n",
    "                unit_pred = (self.unit_pred[template][0][0], self.unit_pred[template][0][1], 0)\n",
    "                self.unit_errors[template] = math.dist(xyzreal, unit_pred)\n",
    "            else:\n",
    "                unit_pred_1 = (self.unit_pred[template][0][0], self.unit_pred[template][0][1], self.unit_pred[template][0][2])\n",
    "                unit_pred_2 = (self.unit_pred[template][0][0], self.unit_pred[template][0][1], -self.unit_pred[template][0][2])\n",
    "                self.unit_errors[template] = min(math.dist(xyzreal, unit_pred_1), math.dist(xyzreal, unit_pred_2))\n",
    "        \n",
    "        self.median_errors = [np.median(self.pred_errors[template]) for template in range (self.n_templates)]\n",
    "        self.std_errors = [np.std(self.pred_errors[template]) for template in range (self.n_templates)]\n",
    "    \n",
    "    def alpha_and_z(self) :\n",
    "        '''\n",
    "        When a location is estimated by spike interface, it is done in 3 dimensions and with an estimation of the spike amplitude (alpha)\n",
    "        Here we get the predicted z positions and the alpha values \n",
    "        '''\n",
    "        self.z_values = [0]*self.n_templates\n",
    "        self.alpha_values = [0]*self.n_templates\n",
    "        for template in range(self.n_templates) :\n",
    "            self.z_values[template] = [self.locations_pred[template][time][2] for time in range (len(self.locations_pred[template]))]\n",
    "            self.alpha_values[template]= [self.locations_pred[template][time][3] for time in range (len(self.locations_pred[template]))]\n",
    "        \n",
    "    def templates_features(self):\n",
    "        '''\n",
    "        We want to understand why some templates positions are better predicted than others.\n",
    "        We hypothetized that the variance of the peak to peak and the frobenius norms could affect the localisation in spike interface\n",
    "        So here we compute these values for the templates of interest \n",
    "        '''\n",
    "        self.templates_infos = {\n",
    "            'Peak to peak variances' : [] , 'Frobenius norms' : []\n",
    "        }\n",
    "        for template_id in self.template_ids :\n",
    "            ptp = [np.max(self.templates[template_id][probe][:]) - np.min(self.templates[template_id][probe][:]) for probe in range(self.n_probes)]\n",
    "            self.templates_infos['Peak to peak variances'].append(np.var(ptp))\n",
    "            self.templates_infos['Frobenius norms'].append(np.linalg.norm(self.templates[template_id]))\n",
    "\n",
    "    def excitatory_or_inhibitory(self) :\n",
    "        '''\n",
    "        Excitatory and inhibitory cells exhibit different spike shapes\n",
    "        So here we identify the templates coming from excitatory cells/inhibitory \n",
    "        '''\n",
    "        self.exc_num = []\n",
    "        self.inh_num = []\n",
    "        exc = ['STPC', 'TTPC1', 'TTPC2', 'UTPC'] \n",
    "        inh = ['BP', 'BTC', 'ChC', 'DBC', 'LBC', 'MC', 'NBC', 'NGC', 'SBC']\n",
    "        for num, template in enumerate(self.template_ids) :\n",
    "            for celltype in exc :\n",
    "                if celltype in self.tempgen.celltypes[template] :\n",
    "                    self.exc_num.append(num)\n",
    "            for celltype in inh :\n",
    "                if celltype in self.tempgen.celltypes[template] :\n",
    "                    self.inh_num.append(num)\n",
    "\n",
    "\n",
    "    def plot_parameters(self, n_to_plot = 15) :\n",
    "        cmap = cm.get_cmap('PuBuGn')\n",
    "        if self.n_templates < n_to_plot :\n",
    "            self.n_to_plot = self.n_templates\n",
    "        else :\n",
    "            self.n_to_plot = n_to_plot\n",
    "        self.colors = [cmap(c/n_to_plot) for c in range (n_to_plot)]\n",
    "\n",
    "    def plot_predictions (self, n_to_plot=15) :\n",
    "        '''\n",
    "        Function to plot the predicted locations(small dots) and the real positions (large dots) \n",
    "        '''\n",
    "        self.plot_parameters(n_to_plot)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6,8))\n",
    "        plot_probe(self.recording_si.get_probe(), ax=ax)\n",
    "        for template in range (self.n_to_plot) : \n",
    "            x_pred = [self.locations_pred[template][t][0] for t in range (len(self.locations_pred[template]))]\n",
    "            y_pred = [self.locations_pred[template][t][1] for t in range (len(self.locations_pred[template]))]\n",
    "            plt.scatter(x_pred, y_pred, s = 20, edgecolors= 'none', color = self.colors[template]) \n",
    "        x_real = [self.locations_real[template][1] for template in range (self.n_to_plot)]\n",
    "        y_real = [self.locations_real[template][2] for template in range (self.n_to_plot)]\n",
    "        x_unit = [self.unit_pred[template][0][0] for template in range (self.n_to_plot)]\n",
    "        y_unit = [self.unit_pred[template][0][1] for template in range (self.n_to_plot)]\n",
    "        plt.scatter(x_real, y_real, s=100, color = self.colors, edgecolors= 'black', marker = '*')  \n",
    "        plt.scatter(x_unit, y_unit, s=100, color = self.colors, edgecolors= 'black')\n",
    "        plt.title('Predicted positions compared to real positions')\n",
    "        plt.xlabel('x coordinate in um')\n",
    "        plt.ylabel('y coordinate in um')\n",
    "        plt.show()\n",
    "\n",
    "    def boxplot_errors(self, n_to_plot=15) :\n",
    "        '''\n",
    "        For each template multiple location predictions are made and this function helps to visualize the range of errors for each template \n",
    "        '''\n",
    "        self.plot_parameters(n_to_plot)\n",
    "        fig = plt.figure(figsize =(12, 8))\n",
    "        ax = plt.subplot()\n",
    "        bp = plt.boxplot(self.pred_errors[:self.n_to_plot], 0, '', patch_artist=True)\n",
    "        ax.set_xticklabels([f\"#{i}\" for i in range (self.n_to_plot)]) # We only show a maximum of 10 boxplots for readibility\n",
    "        ax.set_ylabel('Prediction error in um')\n",
    "        ax.set_xlabel('Templates')\n",
    "        ax.set_title('Distance between template position and spike location')\n",
    "        for patch, color in zip(bp['boxes'], self.colors):\n",
    "            patch.set_facecolor(color)      \n",
    "        plt.show()\n",
    "\n",
    "    def plot_error_against_features (self):\n",
    "        '''\n",
    "        Now this functions gives us a vizualization of a potential relation between the extracted features and the localization errors \n",
    "        '''\n",
    "        self.templates_features()\n",
    "        self.excitatory_or_inhibitory()\n",
    "        y_titles = list(self.templates_infos.keys())\n",
    "        fig, ax = plt.subplots(len(y_titles), figsize = (8,10))\n",
    "        fig.suptitle = 'Plot ' + self.probe\n",
    "        for n in range(len(y_titles)):\n",
    "            for num in self.exc_num :\n",
    "                ax[n].scatter(self.templates_infos[y_titles[n]][num], self.median_errors[num],color = 'green')\n",
    "            for num in self.inh_num :\n",
    "                ax[n].scatter(self.templates_infos[y_titles[n]][num], self.median_errors[num], color = 'red')\n",
    "            ax[n].set_ylabel('Prediction error in um')\n",
    "            ax[n].set_xlabel(y_titles[n])\n",
    "\n",
    "        plt.show()\n",
    "        return()\n",
    "\n",
    "\n",
    "\n",
    "    def predictor(self, feature) :\n",
    "        '''\n",
    "        We hypothesize that the feature and the error are inversely proportional \n",
    "        '''\n",
    "        xarray = np.array(self.templates_infos[feature])\n",
    "        yarray = np.array([1/yi for yi in self.median_errors])\n",
    "        X = np.vstack([xarray, np.ones(len(xarray))]).T\n",
    "        model = np.linalg.lstsq(X,yarray, rcond=None)\n",
    "        self.slope = model[0][0]\n",
    "        self.rectification = model[1][0]\n",
    "\n",
    "    def plot_fit_curve(self, feature) :\n",
    "        '''\n",
    "        We show the fitted curve compared to the real curve \n",
    "        '''\n",
    "        plt.scatter(self.templates_infos[feature], self.median_errors, color = 'blue')\n",
    "        x_fit = range(int(max(self.templates_infos[feature])))\n",
    "        y_fit = [1/(self.slope*xi+self.rectification) for xi in x_fit]\n",
    "        plt.scatter(x_fit, y_fit, color = 'black')\n",
    "        plt.title(f\"Finding a model for predicting the error based on the {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_data = {}\n",
    "methods = 'center_of_mass', 'monopolar_triangulation'\n",
    "probe = 'Fake_probe'\n",
    "timing = {}\n",
    "t = 1\n",
    "t_2 = 1.5 \n",
    "r = 50\n",
    "\n",
    "for method in methods: \n",
    "    mea_data[method] = artificial_data(files_folder, probe)\n",
    "    print('initialisation done')\n",
    "    mea_data[method].load_in_spike_interface() \n",
    "    print('Data loaded in Spike Interface')\n",
    "    timing[method] = time.time() \n",
    "    mea_data[method].predicted_locations(method = method, ms_before = t, ms_after = t, radius_um = r)\n",
    "    timing[method] = time.time()  - timing[method]\n",
    "    print('Locations predicted')\n",
    "    mea_data[method].find_errors() \n",
    "    print('Errors found, plotting starting')\n",
    "    mea_data[method].plot_predictions()\n",
    "    mea_data[method].boxplot_errors() \n",
    "    mea_data[method].plot_error_against_features()\n",
    "\n",
    "print(timing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'monopolar_triangulation'\n",
    "probe = 'Fake_probe'\n",
    "\n",
    "t = 0.4\n",
    "t_2 = 0.4\n",
    "r = 45\n",
    "\n",
    "mea_data_opti = artificial_data(files_folder, probe)\n",
    "print('initialisation done')\n",
    "mea_data_opti.load_in_spike_interface() \n",
    "print('Data loaded in Spike Interface')\n",
    "time_opti = time.time() \n",
    "mea_data_opti.predicted_locations(method = method, ms_before = t, ms_after = t, radius_um = r)\n",
    "time_opti = time.time()  - time_opti\n",
    "print('Locations predicted')\n",
    "\n",
    "print(time_opti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at real data (ground truth recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class real_data_templates:\n",
    "    def __init__(self, file, probe) :\n",
    "        self.file = file \n",
    "        self.templates = np.load(file)\n",
    "        self.templates = np.array(self.templates).T.tolist()\n",
    "        self.probe = probe\n",
    "\n",
    "    \n",
    "    def templates_in_recording (self) :\n",
    "        self.n_templates = len(self.templates)\n",
    "        self.template_ids = range(self.n_templates)\n",
    "        self.n_probes = len(self.templates[0])\n",
    "\n",
    "    def templates_features(self):\n",
    "        self.templates_in_recording()\n",
    "        self.template_infos = {\n",
    "            'Peak to peak variances' : [] , 'Frobenius norms' : []\n",
    "        }\n",
    "        for template_id in self.template_ids :\n",
    "            ptp = [np.max(self.templates[template_id][probe][:]) - np.min(self.templates[template_id][probe][:]) for probe in range(self.n_probes)]\n",
    "            self.template_infos['Peak to peak variances'].append(np.var(ptp))\n",
    "            self.template_infos['Frobenius norms'].append(np.linalg.norm(self.templates[template_id]))\n",
    "\n",
    "    def predict_error(self, feature, slope, rectification) :\n",
    "        self.templates_features()\n",
    "        x_fit = self.template_infos[feature]\n",
    "        y_fit = [1/(slope*xi+rectification) for xi in x_fit]\n",
    "        plt.scatter(x_fit, y_fit, color = 'black')\n",
    "        plt.title(f\"Predicting the error based on the {feature} for real data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_recording = 30\n",
    "sampling_frequency=20000\n",
    "\n",
    "class real_data_recordings :\n",
    "    def __init__(self,folder, probe, rec) :\n",
    "        self.rec = rec\n",
    "        self.folder = folder\n",
    "        self.probe = probe\n",
    "        recording_si = si.read_mcsraw(f\"{folder}recordings\\\\{rec}\\\\{rec}.raw\")\n",
    "        recording_si.annotate(is_filtered=True)\n",
    "        recording_si = recording_si.frame_slice(0,sampling_frequency*time_recording) #30 secondes\n",
    "        self.recording_si = recording_si.set_probegroup(read_prb(f\"{folder}\\\\{probe}.prb\"))\n",
    "        juxta = si.read_binary(f\"{folder}recordings\\\\{rec}\\\\{rec}.juxta.raw\", sampling_frequency=sampling_frequency, num_chan=1, dtype='float32')\n",
    "        peaks = detect_peaks(juxta, exclude_sweep_ms=2, detect_threshold=8)\n",
    "        times = peaks['sample_ind']\n",
    "        times = np.array([t for t in times if t<sampling_frequency*time_recording])\n",
    "        self.sorting_si = si.NumpySorting.from_times_labels(times, np.zeros(len(times)), sampling_frequency=sampling_frequency)\n",
    "        \n",
    "    def predicted_locations (self, method = 'monopolar_triangulation') :\n",
    "        wv_real = si.extract_waveforms(recording = self.recording_si, sorting= self.sorting_si, overwrite= False, folder=f\"{self.folder}waveforms\\\\waforms_{self.rec}_{method}\", load_if_exists=True, max_spikes_per_unit=None)\n",
    "        self.locations_pred  = si.compute_spike_locations(wv_real, method = method) \n",
    "        self.unit_pred = si.compute_unit_locations(wv_real, method = method) \n",
    "\n",
    "    def find_error (self, real_positions) :\n",
    "        self.locations_real = real_positions\n",
    "        self.pred_errors = [math.dist((pred[0],pred[1]), self.locations_real) for pred in self.locations_pred]\n",
    "        self.median_errors = np.median(self.pred_errors)\n",
    "        self.std_errors = np.std(self.pred_errors)\n",
    "        self.unit_error = math.dist(self.locations_real, (self.unit_pred[0][0], self.unit_pred[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiple_recordings :\n",
    "    def __init__(self, recording_objects) :\n",
    "        self.n_recordings = len(recording_objects.keys())\n",
    "        self.locations_real = [recording_objects[key].locations_real for key in recording_objects.keys()]\n",
    "        self.locations_pred = [recording_objects[key].locations_pred for key in recording_objects.keys()]\n",
    "        self.unit_pred = [recording_objects[key].unit_pred for key in recording_objects.keys()]\n",
    "        self.pred_errors = [recording_objects[key].pred_errors for key in recording_objects.keys()]\n",
    "        self.unit_errors = [recording_objects[key].unit_error for key in recording_objects.keys()]\n",
    "        self.recording_si = [recording_objects[key].recording_si for key in recording_objects.keys()]\n",
    "        self.median_errors = [recording_objects[key].median_errors for key in recording_objects.keys()]\n",
    "        self.std_errors = [recording_objects[key].std_errors for key in recording_objects.keys()]\n",
    "        \n",
    "    def plot_parameters(self) :\n",
    "        cmap = cm.get_cmap('PuBuGn')\n",
    "        self.colors = [cmap(c/self.n_recordings) for c in range (self.n_recordings)]\n",
    "    \n",
    "    def plot_predictions (self, probe_object) :\n",
    "        self.plot_parameters()\n",
    "        #plot_probe(probe_object)\n",
    "        plot_probe(mea_data[method].recording_si.get_probe())\n",
    "        for rec in range (len(self.locations_real)) :\n",
    "            x_pred = [pred[0] for pred in self.locations_pred[rec]]\n",
    "            y_pred = [pred[1] for pred in self.locations_pred[rec]]\n",
    "            plt.scatter(x_pred, y_pred, s = 20, edgecolors= 'none', color = self.colors[rec]) # the predictions are represented by small dots \n",
    "            plt.scatter(self.locations_real[rec][0], self.locations_real[rec][1], s=100, color = self.colors[rec],  edgecolors= 'black', marker = '*') \n",
    "            plt.scatter(self.unit_pred[rec][0][0], self.unit_pred[rec][0][1], s=100, color = self.colors[rec],  edgecolors= 'black')\n",
    "            plt.title('Predictions vs positions')\n",
    "            plt.xlabel('x coordinate in um')\n",
    "            plt.ylabel('y coordinate in um')\n",
    "\n",
    "\n",
    "    def violinplot_errors(self, colors) :\n",
    "        self.plot_parameters()\n",
    "        plt.figure()\n",
    "        ax = plt.subplot()\n",
    "        vp = plt.violinplot(self.pred_errors,  showmedians=True, showextrema=False)\n",
    "        ax.set_ylabel('Location error (µm)', fontsize=13)\n",
    "        ax.tick_params(axis='both', which='both', labelsize=11)\n",
    "        ax.set_xticks([],[])\n",
    "        ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "        for body, color in zip(vp['bodies'], colors): \n",
    "            body.set_color(color)\n",
    "            body.set_edgecolor('black')\n",
    "            body.set_alpha(1)\n",
    "        for key in vp.keys():\n",
    "            if key != 'bodies':\n",
    "                vp[key].set_edgecolor('black') \n",
    "        for n in range (self.n_recordings):\n",
    "            plt.scatter(n+1,self.unit_errors[n], color = colors[n], edgecolors= 'black', s=50, linewidths=2, marker='o')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe ='mea_256'\n",
    "probe_object = read_prb(f\"{working_folder}\\\\data_real\\\\{probe}.prb\")\n",
    "for method in methods: \n",
    "    physio_templates = real_data_templates(templates_file, probe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = probe_object.to_dict()\n",
    "channel_positions = p['probes'][0]['contact_positions']\n",
    "\n",
    "real_positions = {'20160426_patch3' : channel_positions[226] + [5,-4],\n",
    "                  '20170726_patch1' : channel_positions[30] + [6,6],\n",
    "                  '20170728_patch2' : channel_positions[118] + [-2,9],\n",
    "                  '20160426_patch2' : channel_positions[200] + [-18, -12], \n",
    "                  '20160415_patch2' : channel_positions[69] +  [3,-15]}\n",
    "                  \n",
    "physio_recordings = {}\n",
    "for method in methods : \n",
    "    physio_recordings[method] = {}\n",
    "    for rec in listdir(working_folder + 'data_real\\\\recordings'): \n",
    "        folder = f\"{working_folder}data_real\\\\\"\n",
    "        physio_recordings[method][rec] = real_data_recordings(folder, probe, rec)\n",
    "        physio_recordings[method][rec].predicted_locations(method = method)\n",
    "        physio_recordings[method][rec].find_error(real_positions[rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physio_all_recordings = {}\n",
    "maps = {'center_of_mass':'Blues', 'monopolar_triangulation' :'Purples'}\n",
    "for method in methods:\n",
    "    physio_all_recordings[method] = multiple_recordings(physio_recordings[method])\n",
    "    physio_all_recordings[method].plot_predictions(probe_object)\n",
    "    cmapp = cm.get_cmap(maps[method])\n",
    "    colors = [cmapp(c/len(listdir(working_folder + 'data_real\\\\recordings'))) for c in range (len(listdir(working_folder + 'data_real\\\\recordings')))]\n",
    "    physio_all_recordings[method].violinplot_errors(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for poster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots_methods(dico, n_to_plot, xy_ind_real) :\n",
    "    fig, axes = plt.subplots(nrows= 1, ncols= len(methods), figsize=(22,12))\n",
    "    \n",
    "    x,y = xy_ind_real\n",
    "    for m,method in enumerate(methods):\n",
    "        self = dico[method]\n",
    "        cmap = cmaps[m]\n",
    "        self.colors = [cmap(c/n_to_plot) for c in range (n_to_plot)]\n",
    "        if type(self.recording_si) == list:\n",
    "            recording = self.recording_si[0]\n",
    "        else :\n",
    "            recording = self.recording_si\n",
    "        si.plot_probe_map(recording, with_channel_ids=False, ax=axes[m])\n",
    "        for template in range (n_to_plot) : \n",
    "            x_pred = [self.locations_pred[template][t][0] for t in range (len(self.locations_pred[template]))]\n",
    "            y_pred = [self.locations_pred[template][t][1] for t in range (len(self.locations_pred[template]))]\n",
    "            axes[m].scatter(x_pred, y_pred, s = 50, edgecolors= 'none', color = self.colors[template])     \n",
    "        x_real = [self.locations_real[template][x] for template in range (n_to_plot)]\n",
    "        y_real = [self.locations_real[template][y] for template in range (n_to_plot)]\n",
    "        x_unit = [self.unit_pred[template][0][0] for template in range (n_to_plot)]\n",
    "        y_unit = [self.unit_pred[template][0][1] for template in range (n_to_plot)]\n",
    "        axes[m].scatter(x_real, y_real, s=500, color = self.colors, edgecolors= 'black', marker = '*', linewidth=2, label = 'Real position')  \n",
    "        axes[m].scatter(x_unit, y_unit, s=400, color = self.colors, edgecolors= 'black', linewidth=2, label = 'Averaged template')\n",
    "        axes[m].set_title((method.replace('_',' ')).capitalize(), fontsize=30, pad =10)\n",
    "        axes[m].set_ylabel('')\n",
    "        axes[m].set_xlabel('')\n",
    "        axes[m].scatter(-300, -300, marker = '.', s= 100, color = 'black', label = 'Individual spike')\n",
    "        axes[m].set_xticks([],[])\n",
    "        axes[m].set_yticks([],[])\n",
    "        fontprops = fm.FontProperties(size=22)\n",
    "        scalebar = AnchoredSizeBar(axes[m].transData,\n",
    "                           100, '100 µm', 'lower right', \n",
    "                           pad=0.5,\n",
    "                           color='black',\n",
    "                           frameon=False,\n",
    "                           size_vertical=1, fontproperties=fontprops)\n",
    "\n",
    "        axes[0].add_artist(scalebar)\n",
    "        fig.tight_layout(pad=2)\n",
    "        plt.legend(loc = 'lower right', fontsize = 24)\n",
    "    \n",
    "\n",
    "\n",
    "subplots_methods(mea_data, 30, (1,2))\n",
    "subplots_methods(physio_all_recordings, 5, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2\n",
    "center = (0,0)\n",
    "colors_binary_fill = cmaps[0](0.4), cmaps[1](0.4)\n",
    "\n",
    "def errors_fct_dist(object, sigma, center, xyreal): \n",
    "    (a,b) = xyreal\n",
    "    maxi = 0\n",
    "    fig, axes_all = plt.subplots(nrows= 3, ncols= 2, figsize=(14,12)) \n",
    "    features = 'Frobenius norms', 'Peak to peak variances'\n",
    "    ax = axes_all[0]\n",
    "\n",
    "    vps = [0,0]\n",
    "    vps[0] = ax[0].violinplot([object[methods[0]].median_errors,  object[methods[1]].median_errors, object[methods[0]].std_errors,  object[methods[1]].std_errors], showmedians=True, showextrema=False)\n",
    "    vps[1] = ax[1].violinplot([object[methods[0]].unit_errors, object[methods[1]].unit_errors], showmedians=True, showextrema=False)\n",
    "    \n",
    "    ax[0].set_ylabel('Location error (µm)', fontsize=20)\n",
    "\n",
    "    colors_binary_plus = colors_binary + colors_binary\n",
    "    for vp in vps: \n",
    "        for body, color in zip(vp['bodies'], colors_binary_plus): \n",
    "            body.set_color(color)\n",
    "            body.set_alpha(0.7)\n",
    "            body.set_edgecolor('black')\n",
    "            body.set_linewidth(2)\n",
    "        for key in vp.keys():\n",
    "            if key != 'bodies':\n",
    "                vp[key].set_edgecolor('black') \n",
    "                \n",
    "\n",
    "    ax[0].set_xticks([1.5,3.5],['Median', 'Standard deviation'])\n",
    "    ax[1].set_xticks([],[])\n",
    "\n",
    "    for n in range (len(ax)) : \n",
    "        ax[n].tick_params(axis='both', which='both', labelsize=18)\n",
    "        ax[n].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "        ax[n].set_ylim([0,200])\n",
    "\n",
    "\n",
    "    ax[0].set_title('Individual spike', fontsize = 25, pad=15)\n",
    "    ax[1].set_title('Averaged template', fontsize = 25, pad=15)\n",
    "    \n",
    "\n",
    "    axes = axes_all[1]\n",
    "\n",
    "    for m,method in enumerate(methods):\n",
    "        self = object[method]\n",
    "        self.distances = []\n",
    "        self.stds = []\n",
    "\n",
    "        for template in range (len(self.locations_real)) :\n",
    "            x = self.locations_real[template][a]\n",
    "            y = self.locations_real[template][b]\n",
    "            self.distances.append(math.dist((x,y), center))\n",
    "            self.stds.append(np.std(self.pred_errors[template]))\n",
    "\n",
    "        self.order = np.argsort(np.array(self.distances))\n",
    "        sorted_d = [self.distances[i] for i in self.order]\n",
    "        sorted_error = [self.median_errors[i] for i in self.order]\n",
    "        sorted_std_down = [self.median_errors[i] - self.stds[i] for i in self.order]\n",
    "        sorted_std_up = [self.median_errors[i] + self.stds[i] for i in self.order]\n",
    "\n",
    "        self.unit_std= np.std(self.unit_errors)\n",
    "        sorted_unit_error = [self.unit_errors[i] for i in self.order]\n",
    "\n",
    "        if sigma is not None:\n",
    "            sorted_error = gaussian_filter1d(sorted_error, sigma=sigma)\n",
    "            sorted_std_down = gaussian_filter1d(sorted_std_down, sigma=sigma)\n",
    "            sorted_std_up = gaussian_filter1d(sorted_std_up, sigma=sigma)\n",
    "            sorted_unit_error = gaussian_filter1d(sorted_unit_error, sigma=sigma)\n",
    "\n",
    "\n",
    "        maxi = np.max([maxi,np.max(sorted_std_up)])\n",
    "        axes[0].plot(sorted_d, sorted_error, color = colors_binary[m], label = (method.replace('_', ' ')).capitalize(), linewidth=4)\n",
    "        axes[0].fill_between(sorted_d, sorted_std_down, y2= sorted_std_up, color = colors_binary_fill[m], alpha=0.5, edgecolor=None)\n",
    "        axes[0].set_ylabel('Location error (µm)', fontsize = 20)\n",
    "\n",
    "        axes[1].plot(sorted_d, sorted_unit_error, color = colors_binary[m], label = (method.replace('_', ' ')).capitalize(), linewidth=4)\n",
    "\n",
    "    for n in range (len(axes)) : \n",
    "        axes[n].set_xlabel('Distance from center (µm)', fontsize = 20)  \n",
    "        axes[n].set_xlim([np.min(self.distances), np.max(self.distances)])\n",
    "        axes[n].set_ylim([0,150])\n",
    "        axes[n].tick_params(axis='both', which='both', labelsize=18)\n",
    "        axes[n].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "    axes = axes_all[2]\n",
    "    \n",
    "    for m,method in enumerate(methods):\n",
    "        self = object[method]\n",
    "\n",
    "        self.order = np.argsort(np.array(self.templates_infos[features[0]]))\n",
    "        sorted_f = [self.templates_infos[features[0]][i] for i in self.order]\n",
    "        sorted_error = [self.median_errors[i] for i in self.order]\n",
    "        sorted_std_down = [self.median_errors[i] - self.stds[i] for i in self.order]\n",
    "        sorted_std_up = [self.median_errors[i] + self.stds[i] for i in self.order]\n",
    "\n",
    "        self.unit_std= np.std(self.unit_errors)\n",
    "        sorted_unit_error = [self.unit_errors[i] for i in self.order]\n",
    "\n",
    "        if sigma is not None:\n",
    "            sorted_error = gaussian_filter1d(sorted_error, sigma=sigma)\n",
    "            sorted_std_down = gaussian_filter1d(sorted_std_down, sigma=sigma)\n",
    "            sorted_std_up = gaussian_filter1d(sorted_std_up, sigma=sigma)\n",
    "            sorted_unit_error = gaussian_filter1d(sorted_unit_error, sigma=sigma)\n",
    "\n",
    "        maxi = np.max([maxi,np.max(sorted_std_up)])\n",
    "        axes[0].plot(sorted_f, sorted_error, color = colors_binary[m], label = (method.replace('_', ' ')).capitalize(), linewidth=4)\n",
    "        axes[0].fill_between(sorted_f, sorted_std_down, y2= sorted_std_up, color = colors_binary_fill[m], alpha=0.5, edgecolor=None)\n",
    "        axes[0].set_ylabel('Location error (µm)', fontsize = 20)\n",
    "\n",
    "        axes[1].plot(sorted_f, sorted_unit_error, color = colors_binary[m], label = (method.replace('_', ' ')).capitalize(), linewidth=4)\n",
    "\n",
    "    for n in range (len(axes)) : \n",
    "        axes[n].set_xlabel('L2 norm', fontsize = 20)  \n",
    "        axes[n].set_xlim([np.min(sorted_f), np.max(sorted_f)])\n",
    "        axes[n].set_ylim([0,120])\n",
    "        axes[n].tick_params(axis='both', which='both', labelsize=18)\n",
    "        axes[n].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "    for ax in axes_all:\n",
    "        ax[1].spines['left'].set_visible(False)\n",
    "        ax[1].set_yticks([],[])\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "errors_fct_dist(mea_data, sigma, center, (1,2))\n",
    "errors_fct_dist(physio_all_recordings, sigma, center, (0,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_data['monopolar_triangulation'].alpha_and_z()\n",
    "\n",
    "alpha_median = []\n",
    "alpha_std = []\n",
    "z_median = []\n",
    "z_std = []\n",
    "\n",
    "for template in range (mea_data['monopolar_triangulation'].n_templates) :\n",
    "    alpha_median.append(np.median(mea_data['monopolar_triangulation'].alpha_values[template]))\n",
    "    alpha_std.append(np.std(mea_data['monopolar_triangulation'].alpha_values[template]))\n",
    "    z_median.append(np.median(mea_data['monopolar_triangulation'].z_values[template]))\n",
    "    z_std.append(np.std(mea_data['monopolar_triangulation'].z_values[template]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows= 1, ncols= 2, figsize=(22,6)) \n",
    "colors_type = ['forestgreen', 'firebrick']\n",
    "for m,method in enumerate(methods):\n",
    "    mea_data[method].excitatory_or_inhibitory()\n",
    "    errors_exc_unit = [mea_data[method].unit_errors[template] for template in mea_data[method].exc_num]\n",
    "    errors_inh_unit = [mea_data[method].unit_errors[template] for template in mea_data[method].inh_num]\n",
    "    vp = ax[m].violinplot([errors_exc_unit, errors_inh_unit], showmedians=True, showextrema=False)\n",
    "    for body, color, edge in zip(vp['bodies'], [colors_binary[m],colors_binary[m]], colors_type): \n",
    "        body.set_color(color)\n",
    "        body.set_alpha(0.7)\n",
    "        body.set_edgecolor('black')\n",
    "        body.set_linewidth(3)\n",
    "    for key in vp.keys():\n",
    "        if key != 'bodies':\n",
    "            vp[key].set_edgecolor('black') \n",
    "    ax[m].tick_params(axis='both', which='both', labelsize=18)\n",
    "    ax[m].set_xticks([1,2],['Exc', 'Inh'])\n",
    "\n",
    "    for ticklabel,tickcolor in zip(ax[m].get_xticklabels(), colors_type):\n",
    "        ticklabel.set_color(tickcolor)\n",
    "        ticklabel.set_fontsize(25)\n",
    "\n",
    "    ax[m].set_ylim([0,180])\n",
    "    ax[m].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "ax[1].set_yticks([],[])\n",
    "ax[1].spines['left'].set_visible(False)\n",
    "ax[0].set_ylabel('Location error (µm)', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_patch(legend, handle, label):\n",
    "    ax = legend.axes\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(handle)\n",
    "    labels.append(label)\n",
    "    legend._legend_box = None\n",
    "    legend._init_legend_box(handles, labels)\n",
    "    legend._set_loc(legend._loc)\n",
    "    legend.set_title(legend.get_title().get_text())\n",
    "\n",
    "\n",
    "class ImageHandler(HandlerBase):\n",
    "    def create_artists(self, legend, orig_handle,\n",
    "                       xdescent, ydescent, width, height, fontsize,\n",
    "                       trans):\n",
    "\n",
    "        # enlarge the image by these margins\n",
    "        sx, sy = self.image_stretch \n",
    "\n",
    "        # create a bounding box to house the image\n",
    "        bb = Bbox.from_bounds(xdescent - sx,\n",
    "                              ydescent - sy + 12,\n",
    "                              width + sx,\n",
    "                              height + sy)\n",
    "\n",
    "        tbb = TransformedBbox(bb, trans)\n",
    "        image = BboxImage(tbb)\n",
    "        image.set_data(self.image_data)\n",
    "\n",
    "        self.update_prop(image, orig_handle, legend)\n",
    "\n",
    "        return [image]\n",
    "\n",
    "\n",
    "    def set_image(self, image_path, image_stretch=(0, 0)):\n",
    "        self.image_data = plt.imread(image_path)\n",
    "        self.image_stretch = image_stretch\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "for m,method in enumerate(methods):\n",
    "    self = physio_all_recordings[method]\n",
    "    cmapp = cm.get_cmap(maps[method])\n",
    "    colors = [cmapp(c/len(listdir(working_folder + 'data_real\\\\recordings'))) for c in range (len(listdir(working_folder + 'data_real\\\\recordings')))]\n",
    "    vp = ax[m].violinplot(self.pred_errors,  showmedians=True, showextrema=False)\n",
    "    ax[0].set_ylabel('Location error (µm)', fontsize=20)\n",
    "    ax[m].set_ylim([0,200])\n",
    "    ax[m].tick_params(axis='both', which='both', labelsize=16)\n",
    "    ax[m].set_xticks([],[])\n",
    "    ax[1].set_yticks([],[])\n",
    "    ax[m].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax[1].spines['left'].set_visible(False)\n",
    "    for body, color in zip(vp['bodies'], colors): \n",
    "        body.set_color(color)\n",
    "        body.set_edgecolor('black')\n",
    "        body.set_alpha(1)\n",
    "        body.set_linewidth(2)\n",
    "    for key in vp.keys():\n",
    "        if key != 'bodies':\n",
    "            vp[key].set_edgecolor('black') \n",
    "    for n in range (self.n_recordings):\n",
    "        if (m,n) == (0,0):\n",
    "            a = ax[m].scatter(n+1,self.unit_errors[n], color = colors[n], edgecolors= 'black', s=300, linewidth=2, marker='o')\n",
    "        if (m,n) == (0,1):\n",
    "            b = ax[m].scatter(n+1,self.unit_errors[n], color = colors[n], edgecolors= 'black', s=300, linewidth=2, marker='o')\n",
    "        else : \n",
    "            ax[m].scatter(n+1,self.unit_errors[n], color = colors[n], edgecolors= 'black', s=300, linewidth=2, marker='o')\n",
    "\n",
    "\n",
    "\n",
    "custom_handler = ImageHandler()\n",
    "custom_handler.set_image(\"./poster/vp_symbol.png\",image_stretch=(8, 16))\n",
    "\n",
    "custom_handler2 = ImageHandler()\n",
    "custom_handler2.set_image(\"./poster/circle.png\",image_stretch=(6, 18))\n",
    "\n",
    "fig.legend([a, b],['Individual spike', 'Averaged template'], handler_map={a: custom_handler, b: custom_handler2},labelspacing=2, frameon=False, fontsize=15, bbox_to_anchor=(0.36, 0.87), loc=\"upper center\",  bbox_transform=fig.transFigure)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "cmap = cm.get_cmap(maps[1])\n",
    "colors = [cmap(c/7) for c in range (1,6)]\n",
    "\n",
    "r = 45\n",
    "vp = ax[0].violinplot([mea_data_params[f\"{t}ms_{r}um\"].median_errors for t in ms],  showmedians=True, showextrema=False)\n",
    "ax[0].set_xticks(range(1,6),ms)\n",
    "ax[0].set_xlabel('Temporal window (ms)', fontsize=18)\n",
    "for body, color in zip(vp['bodies'], colors): \n",
    "    body.set_color(color)\n",
    "    body.set_edgecolor('black')\n",
    "    body.set_alpha(1)\n",
    "    body.set_linewidth(2)\n",
    "    for key in vp.keys():\n",
    "        if key != 'bodies':\n",
    "            vp[key].set_edgecolor('black')\n",
    "\n",
    "t = 1.2\n",
    "all_units = []\n",
    "for r in radius: \n",
    "    all_units.append(mea_data_params[f\"{t}ms_{r}um\"].unit_errors)\n",
    "    \n",
    "vp = ax[1].violinplot(all_units,  showmedians=True, showextrema=False)\n",
    "ax[1].set_xticks(range(1,6),radius)\n",
    "ax[1].set_xlabel('Radius (µm)', fontsize=18)\n",
    "for body, color in zip(vp['bodies'], colors): \n",
    "    body.set_color(color)\n",
    "    body.set_edgecolor('black')\n",
    "    body.set_alpha(1)\n",
    "    body.set_linewidth(2)\n",
    "    for key in vp.keys():\n",
    "        if key != 'bodies':\n",
    "            vp[key].set_edgecolor('black')\n",
    "\n",
    "for m in range(2) : \n",
    "    ax[m].set_ylim([0,125])\n",
    "    ax[m].tick_params(axis='both', which='both', labelsize=16)\n",
    "    ax[m].spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "ax[0].set_ylabel('Location error (µm)', fontsize=18)\n",
    "ax[1].set_yticks([],[])\n",
    "ax[1].spines['left'].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_number = 4\n",
    "time_dur = 12000\n",
    "trace0 = mea_data[method].recording_si.get_traces(segment_index=0, start_frame=0, end_frame=time_dur,channel_ids= [str(i) for i in range (1,11)])\n",
    "trace0=np.array(trace0)\n",
    "trace0 = trace0.T\n",
    "toplot = 4\n",
    "fig, ax = plt.subplots(nrows = toplot, ncols = 1) \n",
    "x = np.array(range(time_dur))\n",
    "x = 0.03125*x\n",
    "for i in range(toplot) :\n",
    "    ax[i].plot(x,trace0[i], color = 'grey')\n",
    "    ax[i].set_ylim(-500,500)\n",
    "    if i != toplot - 1:\n",
    "        ax[i].set_xticks([],[])\n",
    "        ax[i].spines[\"bottom\"]\n",
    "    else :\n",
    "        ax[i].set_xlabel('time (ms)', fontsize='14')\n",
    "    ax[i].set_yticks([],[])\n",
    "    if i != 0 :\n",
    "        ax[i].spines[\"top\"].set_visible(False)\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "#fig, axes = plt.subplots(nrows= 1, ncols= 1, figsize=(22,24))\n",
    "#mr.plot_templates(mea_data[method].tempgen, template_ids=70, drifting=True, cmap='Reds_r', ax = axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_num = mea_data[methods[0]].sorting_si.select_units(['#' + str(template_number)])     \n",
    "wv_num = si.extract_waveforms(recording = mea_data[methods[0]].recording_si, sorting= sorting_num, overwrite= False, folder=f\"{mea_data[methods[0]].folder}//waveforms//wv_{mea_data[methods[0]].probe}_{template_number}\", load_if_exists=True, max_spikes_per_unit=None)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sw.plot_unit_waveforms(wv_num, max_channels=4, unit_colors={'#' + str(template_number): 'indianred'}, ax = ax, same_axis=True, plot_legend = False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_ylim([-220,-150])\n",
    "ax.set_title('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b50c9e5c20b80a7fea53278e7b85976e5483a9191b272239eb7a6e566d7885cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
