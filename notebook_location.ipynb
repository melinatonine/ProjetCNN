{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MEArec as mr # what we will use to create a synthetic recording\n",
    "import spikeinterface.full as si  # what we will use to sort the spikes\n",
    "import matplotlib.pyplot as plt # for plots \n",
    "import math # for calculating \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import yaml # to open parameter files \n",
    "import warnings\n",
    "from probeinterface.plotting import plot_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_folder = \"C:\\\\Users\\\\melin\\\\Anaconda3\\\\envs\\\\si_env\\\\Lib\\\\site-packages\\\\MEArec\\\\cell_models\\\\bbp\" # folder where we downloaded some cell models (13)\n",
    "working_folder = \"C:\\\\Users\\\\melin\\\\Desktop\\\\COURS_M2_CNN\\\\Projet\\\\\" # the current folder \n",
    "param_folder = working_folder + 'params_locations\\\\' # where we put they yaml files with all the parameters\n",
    "files_folder = working_folder + 'temporary_files_locations\\\\' # where we want to put the created files \n",
    "param_ext = '.yml' # yaml files contain dictionaries for our parameters \n",
    "files_ext = \".h5\" # h5 files are created to save what we do \n",
    "parallel_compute = 4 # number of parallel processing that will be ongoing for heavy process \n",
    "real_data = working_folder + 'data_real\\\\templates\\\\full_templates.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_modification(param_folder, list_changes) : \n",
    "    parameters = {\n",
    "    'templates' :{} , \n",
    "    'spiketrains' : {},\n",
    "    'recordings' : {}\n",
    "}\n",
    "    # We read the yaml file for the templates and extract information about the probe \n",
    "    with open(f\"{param_folder}templates{param_ext}\") as file:\n",
    "        try:\n",
    "            parameters['templates'] = yaml.safe_load(file)\n",
    "            for elt in list_changes['templates'] :\n",
    "                if elt in parameters['templates'] :\n",
    "                    parameters['templates'][elt] = list_changes['templates'][elt] \n",
    "                else :\n",
    "                    print('parameter not found')\n",
    "            probe_spe = parameters['templates']['probe']\n",
    "        except yaml.YAMLError as exception:\n",
    "            print(exception)\n",
    "\n",
    "    # We read the yaml file for the spiketrains and extract information about the number of neurons and the duration \n",
    "    with open(f\"{param_folder}spiketrains{param_ext}\") as file:\n",
    "        try:\n",
    "            parameters['spiketrains'] = yaml.safe_load(file)\n",
    "            for elt in list_changes['spiketrains'] :\n",
    "                if elt in parameters['spiketrains'] :\n",
    "                    parameters['spiketrains'][elt] = list_changes['spiketrains'][elt] \n",
    "                else :\n",
    "                    print('parameter not found')\n",
    "            number_neurons = parameters['spiketrains']['n_exc'] + parameters['spiketrains']['n_inh']\n",
    "            duration = parameters['spiketrains']['duration']\n",
    "        except yaml.YAMLError as exception:\n",
    "            print(exception)\n",
    "\n",
    "    # We read the yaml file for the recordings and extract information about the drift\n",
    "    with open(f\"{param_folder}recordings{param_ext}\") as file:\n",
    "        try:\n",
    "            parameters['recordings']= yaml.safe_load(file)\n",
    "            for elt in list_changes['recordings'] :\n",
    "                if elt in parameters['recordings'] :\n",
    "                    parameters['recordings'][elt] = list_changes['recordings'][elt] \n",
    "                else :\n",
    "                    print('parameter not found')\n",
    "            if parameters['recordings']['drifting'] :\n",
    "                drift = True  \n",
    "                start = parameters['recordings']['t_start_drift']\n",
    "            else :\n",
    "                drift = False \n",
    "        except yaml.YAMLError as exception:\n",
    "            print(exception)\n",
    "\n",
    "    # We print the relevant information \n",
    "    print(f\"We create a recording with {number_neurons} neurons, lasting {duration} seconds, from a {probe_spe} probe\")\n",
    "    if drift : \n",
    "        print(f\"The drift starts after {start} seconds\")\n",
    "\n",
    "    return (parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate templates with parameters defined in a yaml file:\n",
    "- what probe we wante to use\n",
    "- the min/max locations of each neuron\n",
    "- the number of templates for each cell model \n",
    "- the drift, if drift = True, we will have multiple templates for each cell at multiple drift steps \n",
    "\n",
    "We create some spike trains (for a chosen number of excitatory/inhibitory neurons and their firing rates) for a specified duration \n",
    "Then based on the templates and the spike trains generated, we can create a recording with again different parameters (noise, constraints on the templates, drift...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_and_saving(params, files_folder, spe='') : \n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") # There are a lot of deprecation warnings that make the ouput not very easy to read, so we ignore them for now \n",
    "\n",
    "        tempgen = mr.gen_templates(cell_models_folder=cell_folder, params=params['templates'], n_jobs=parallel_compute, verbose=False)\n",
    "        \n",
    "        # Then we save the generated template in the output folder put in 'filename'\n",
    "        mr.save_template_generator(tempgen, filename=f\"{files_folder}templates{spe}{files_ext}\", verbose = False)\n",
    "\n",
    "\n",
    "        spgen = mr.gen_spiketrains(params=params['spiketrains'], verbose=False)\n",
    "\n",
    "        recgen = mr.gen_recordings(params=params['recordings'], spgen = spgen, tempgen=tempgen, n_jobs=parallel_compute, verbose=False)\n",
    "\n",
    "        # We also save the recording \n",
    "        mr.save_recording_generator(recgen, filename=f\"{files_folder}recordings{spe}{files_ext}\", verbose=False)\n",
    "    \n",
    "    return tempgen, spgen, recgen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the different parameters files to extract relevant information, as the probe used, the number of neurons, the duration of the recording, or if there is a drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the recording is ready, we open it with spike interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_in_spike_interface(files_folder, spe='') :\n",
    "    return si.read_mearec(f\"{files_folder}recordings{spe}{files_ext}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the generated templates, some were randomly chosen to create our recording, we recover their identification numbers here\n",
    "\n",
    "Using the monopolar triangulation method, spike interface estimates the position of the different units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def templates_in_recording (recgen) :\n",
    "    template_ids = recgen.template_ids\n",
    "    n_templates = len(template_ids)\n",
    "    return template_ids, n_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_locations (recording_si, sorting_si, n_templates, files_folder, spe='', method = 'monopolar_triangulation') :\n",
    "    locations_pred =  [0]*n_templates\n",
    "    for num in range (n_templates) :\n",
    "        sorting_num = sorting_si.select_units([f\"#{num}\"]) # we create a sorting with only one unit \n",
    "        # Then we extract the waveforms corresponding to this unit \n",
    "        wv_num = si.extract_waveforms(recording = recording_si, sorting= sorting_num, overwrite= False, folder=f\"{files_folder}//waveforms//wv{spe}_{num}\", load_if_exists=True, max_spikes_per_unit=None)\n",
    "        \n",
    "        locations_pred[num]  = si.compute_spike_locations(wv_num, method = method) # finally there is the localization of each extracted waveform\n",
    "    return (locations_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compare the real position of each unit (large dots) from MEArec with  all the predictions (small dots) made by spike interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distances (tempgen, locations_pred, n_templates, template_ids, probe, n_to_plot = 15) :\n",
    "    \n",
    "    colors = ['green', 'cadetblue', 'mediumblue', 'slateblue', 'purple', 'plum', 'lightpink', 'gold', 'tomato', 'red', 'darkred', 'saddlebrown', 'black', 'grey', 'white']\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6,8))\n",
    "    plot_probe(probe, ax=ax)\n",
    "\n",
    "    errors = [0]*n_templates\n",
    "    dot_refs_x = [0]*n_templates\n",
    "    dot_refs_y = [0]*n_templates\n",
    "    alpha = []\n",
    "    z = []\n",
    "    alpha_mean = [0]*n_templates\n",
    "\n",
    "    for num in range (n_templates) :\n",
    "\n",
    "        dot_refs_x[num] = tempgen.locations[template_ids[num]][1] # This is the 'real' position of the unit from mearec \n",
    "        dot_refs_y[num] = tempgen.locations[template_ids[num]][2]\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        errors[num] = [0]*len(locations_pred[num])\n",
    "\n",
    "        a = []\n",
    "        for t in range (len(locations_pred[num])) :\n",
    "            dot_pred = locations_pred[num][t][0], locations_pred[num][t][1] # this is the prediction made by spike interface \n",
    "            z.append(locations_pred[num][t][2])\n",
    "            alpha.append(locations_pred[num][t][3]) \n",
    "            a.append(locations_pred[num][t][3])\n",
    "            x.append(dot_pred[0])\n",
    "            y.append(dot_pred[1])   \n",
    "            errors[num][t] = math.dist(dot_pred, (dot_refs_x[num], dot_refs_y[num])) # We compute the distance between the real position and the prediction (norm 2)\n",
    "        \n",
    "        alpha_mean[num] = np.mean(a)\n",
    "        if num < 10 : # We only show a maximum of 10 units so the plot is easier to read \n",
    "            plt.scatter(x, y, s = 20, edgecolors= 'none', color = colors[num]) # the predictions are represented by small dots \n",
    "        \n",
    "\n",
    "    n_plot = min(n_templates, n_to_plot)\n",
    "    # the real positions are represented by larger dots circled in black\n",
    "\n",
    "    plt.scatter(dot_refs_x[:n_plot], dot_refs_y[:n_plot], s=100, color = colors[:n_plot], edgecolors= 'black')  \n",
    "    plt.title('Predictions vs positions')\n",
    "    plt.xlabel('x coordinate in um')\n",
    "    plt.ylabel('y coordinate in um')\n",
    "    plt.show()\n",
    "\n",
    "    return(errors, alpha, z, alpha_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see qualitatively on the above plot that the predictions are not always around the real position. We computed in the precedent loop the distances between the predictions and the reality. We can now plot them to evaluate quantitavely the precision of the monopolar triangulation method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_errors(errors, n_templates, n_to_plot = 15) :\n",
    "        colors = ['green', 'cadetblue', 'mediumblue', 'slateblue', 'purple', 'plum', 'lightpink', 'gold', 'tomato', 'red', 'darkred', 'saddlebrown', 'black', 'grey', 'white']\n",
    "        mean_errors = [0]*n_templates\n",
    "        n_plot = min(len(errors), n_to_plot)\n",
    "\n",
    "        fig = plt.figure(figsize =(12, 8))\n",
    "        ax = plt.subplot()\n",
    "        bp = plt.boxplot(errors[:n_plot], 0, '', patch_artist=True)\n",
    "        ax.set_xticklabels([f\"#{i}\" for i in range (n_plot)]) # We only show a maximum of 10 boxplots for readibility\n",
    "        ax.set_ylabel('Prediction error in um')\n",
    "        ax.set_xlabel('Templates')\n",
    "        ax.set_title('Distance between template position and spike location')\n",
    "\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "                patch.set_facecolor(color)\n",
    "\n",
    "        mean_errors = [np.mean(errors[i]) for i in range (n_templates)]\n",
    "                \n",
    "        plt.show()\n",
    "        return(mean_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location error varies greatly between the different templates, we will now try to understand why. We can test the correlation between the error and different features: \n",
    "- the variation of the peak to peak ratios betweeen the different probes for each template\n",
    "- the frobenius norm of each template matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def templates_info(templates, template_ids, n_templates, spe = \"\"):\n",
    "    \n",
    "    peak_to_peak_var = [0]*n_templates\n",
    "    frob_norms = [0]*n_templates\n",
    "\n",
    "    for i, template_id in enumerate(template_ids) :\n",
    "        n_probe = len(templates[0])\n",
    "        peak_to_peak = [0]*n_probe\n",
    "        for probe in range (n_probe) :\n",
    "            peak_to_peak[probe] = np.max(templates[template_id][probe][:]) - np.min(templates[template_id][probe][:])\n",
    "        peak_to_peak_var[i] = np.var(peak_to_peak)\n",
    "        frob_norms[i] = np.linalg.norm(templates[template_id])\n",
    "\n",
    "    return(peak_to_peak_var,frob_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excitatory_or_inhibitory(tempgen, template_ids, n_templates) :\n",
    "    exc_num = []\n",
    "    inh_num = []\n",
    "    exc = ['STPC', 'TTPC1', 'TTPC2', 'UTPC'] \n",
    "    inh = ['BP', 'BTC', 'ChC', 'DBC', 'LBC', 'MC', 'NBC', 'NGC', 'SBC']\n",
    "    for num in range (n_templates) :\n",
    "        for celltype in exc :\n",
    "            if celltype in tempgen.celltypes[template_ids[num]] :\n",
    "                exc_num.append(num)\n",
    "        for celltype in inh :\n",
    "            if celltype in tempgen.celltypes[template_ids[num]] :\n",
    "                inh_num.append(num)\n",
    "                \n",
    "    return(exc_num, inh_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_vs_y (mean_errors, y_to_plot, y_titles, tempgen, template_ids, n_templates, spe=''):\n",
    "    fig, ax = plt.subplots(len(y_titles), figsize = (8,10))\n",
    "\n",
    "    fig.suptitle = 'Plot ' + spe \n",
    "    exc_num, inh_num = excitatory_or_inhibitory(tempgen, template_ids, n_templates)\n",
    "    for n, y in enumerate(y_to_plot) :\n",
    "        for num in exc_num :\n",
    "            ax[n].scatter(mean_errors[num], y[num], color = 'green')\n",
    "        for num in inh_num :\n",
    "            ax[n].scatter(mean_errors[num], y[num], color = 'red')\n",
    "        ax[n].set_title(y_titles[n])\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_vs_y_all (mean_errors, y_to_plot, y_titles, tempgen, recgen, probes, shapes):\n",
    "\n",
    "    f , ax = plt.subplots(len(y_titles), figsize = (8,10))\n",
    "\n",
    "    for pr in range (len(probes)) :\n",
    "        template_ids, n_templates = templates_in_recording (recgen[pr])\n",
    "        exc_num, inh_num = excitatory_or_inhibitory(tempgen[pr], template_ids, n_templates)\n",
    "\n",
    "        for n, y in enumerate(y_to_plot[pr]) :\n",
    "            for num in exc_num :\n",
    "                ax[n].scatter(mean_errors[pr][num], y[num], color = 'green', marker= shapes[pr])\n",
    "            for num in inh_num :\n",
    "                ax[n].scatter(mean_errors[pr][num], y[num], color = 'red', marker= shapes[pr])\n",
    "            ax[n].set_title(y_titles[n])\n",
    "\n",
    "    plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_probes(mean_errors, probes) :\n",
    "    ax = plt.subplot()\n",
    "    ax.boxplot(mean_errors)\n",
    "    ax.set_xticklabels(probes)\n",
    "    ax.set_ylabel('Distance with real position in um')\n",
    "    ax.set_title('Mean location errors for different probes')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_changes = {\n",
    "    'templates' :{} , \n",
    "    'spiketrains' : {},\n",
    "    'recordings' : {}\n",
    "}\n",
    "\n",
    "probes = ['Fake_probe']\n",
    "\n",
    "tempgen = [0]*len(probes)\n",
    "spgen = [0]*len(probes)\n",
    "recgen = [0]*len(probes)\n",
    "\n",
    "for pr, probe in enumerate(probes) :\n",
    "    list_changes['templates'] = {'probe' : probe}\n",
    "    spe = probe \n",
    "\n",
    "    params = parameters_modification(param_folder, list_changes)\n",
    "\n",
    "    print(f\"parameters successfully modified for {spe}\")\n",
    "\n",
    "    tempgen[pr], spgen[pr], recgen[pr] = generation_and_saving(params, files_folder, spe = spe)\n",
    "\n",
    "    print(f\"Generation done for {spe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probes = ['Fake_probe']\n",
    "shapes = [\"o\", \"^\", \"s\"]\n",
    "\n",
    "tempgen = [0]*len(probes)\n",
    "recgen = [0]*len(probes)\n",
    "\n",
    "locations_pred = [0]*len(probes)\n",
    "\n",
    "for pr, probe in enumerate(probes) :\n",
    "    spe = probe\n",
    "\n",
    "    tempgen[pr] = mr.load_templates(f\"{files_folder}templates{spe}{files_ext}\")\n",
    "    recgen[pr] = mr.load_recordings(f\"{files_folder}recordings{spe}{files_ext}\")\n",
    "\n",
    "    recording_si, sorting_si = load_in_spike_interface(files_folder, spe = spe)\n",
    "\n",
    "    template_ids, n_templates = templates_in_recording(recgen[pr])\n",
    "\n",
    "    locations_pred[pr] = predicted_locations(recording_si, sorting_si, n_templates, files_folder, spe = spe)\n",
    "\n",
    "    print(f\"locations found for {spe}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors = [0]*len(probes)\n",
    "peak_to_peak_var = [0]*len(probes)\n",
    "frob_norms = [0]*len(probes)\n",
    "alpha_values = [0]*len(probes)\n",
    "alpha_mean = [0]*len(probes)\n",
    "z_values = [0]*len(probes)\n",
    "y_to_plot = [0]*len(probes)\n",
    "\n",
    "for pr, probe in enumerate(probes) :\n",
    "    spe = probe\n",
    "\n",
    "    tempgen[pr] = mr.load_templates(f\"{files_folder}templates{spe}{files_ext}\")\n",
    "    recgen[pr] = mr.load_recordings(f\"{files_folder}recordings{spe}{files_ext}\")\n",
    "\n",
    "    recording_si, sorting_si = load_in_spike_interface(files_folder, spe = spe)\n",
    "\n",
    "    template_ids, n_templates = templates_in_recording(recgen[pr])\n",
    "\n",
    "    probe = recording_si.get_probe()\n",
    "    \n",
    "    errors, alpha_values[pr], z_values[pr], alpha_mean[pr] = plot_distances(tempgen[pr], locations_pred[pr], n_templates, template_ids, probe)\n",
    "\n",
    "    mean_errors[pr] = boxplot_errors(errors, n_templates)\n",
    "\n",
    "    templates = tempgen[pr].templates\n",
    "\n",
    "    peak_to_peak_var[pr], frob_norms[pr] = templates_info(templates, template_ids, n_templates, spe=spe)\n",
    "\n",
    "    print(f\"{spe}_ The peak to peak ratios variability are correlated at {np.corrcoef(mean_errors[pr], peak_to_peak_var[pr])[0][1]} with the error\")\n",
    "    print(f\"{spe}_ The Frobenius norms are correlated at {np.corrcoef(mean_errors[pr], frob_norms[pr])[0][1]} with the error\")\n",
    "\n",
    "    y_to_plot[pr] = [peak_to_peak_var[pr], frob_norms[pr]]\n",
    "\n",
    "    end_title = 'in function of the mean location error'\n",
    "\n",
    "    y_titles = ['Peak to peak variance ' + end_title, 'Frobenius norm ' + end_title]\n",
    "\n",
    "    plot_error_vs_y(mean_errors[pr], y_to_plot[pr], y_titles, tempgen[pr], template_ids, n_templates, spe=spe)\n",
    "\n",
    "    print(f\"All done for {probe}\")\n",
    "\n",
    "boxplot_probes(mean_errors, probes)\n",
    "plot_error_vs_y_all(mean_errors, y_to_plot, y_titles, tempgen, recgen, probes, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in range (len(probes)) :\n",
    "    plt.scatter(alpha_values[pr],z_values[pr], marker = '.')\n",
    "\n",
    "plt.title('Relationship between z and amplitude predictions')\n",
    "plt.ylabel('z (um)')\n",
    "plt.xlabel('Alpha (uV)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_real = np.load(real_data)\n",
    "n_templates_real = len(templates_real)\n",
    "template_ids_real = range(n_templates_real)\n",
    "n_channels = len(templates_real[0][0])\n",
    "n_time = len(templates_real[0])\n",
    "\n",
    "print(f\"We loaded data from {n_templates_real} templates, each sampled {n_time} times on {n_channels} channels\")\n",
    "# templates real is n_templates * n_time * n_channels\n",
    "# We want n_templates * n_channels * n_time \n",
    "\n",
    "templates_real_reversed = [0]*n_templates_real \n",
    "for template in template_ids_real :\n",
    "    templates_real_reversed[template] = [0]*n_channels\n",
    "    for channel in range (n_channels) :\n",
    "        templates_real_reversed[template][channel] = [0]*n_time\n",
    "        for time in range (n_time) :\n",
    "            templates_real_reversed[template][channel][time] = templates_real[template][time][channel]\n",
    "\n",
    "peak_to_peak_var_real, frob_norms_real = templates_info(templates_real_reversed, template_ids_real, n_templates_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_use = [0,1]\n",
    "labels_attributes = ['Peak to peak variance', 'Norm']\n",
    "\n",
    "for attribute in attributes_to_use :\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for pr in range (len(probes)) :\n",
    "        for i in range (len(mean_errors[pr])) :\n",
    "            x.append([mean_errors[pr][i]])   \n",
    "        for i in range (len(y_to_plot[pr][attribute])) :\n",
    "            y.append(y_to_plot[pr][attribute][i])\n",
    "            \n",
    "        \n",
    "    ybis = [1/yi for yi in y]\n",
    "\n",
    "    plt.scatter(x,ybis, marker = '.')\n",
    "\n",
    "    xarray = np.array(x)\n",
    "    ybisarray = np.array(ybis)\n",
    "    model = np.linalg.lstsq(xarray,ybisarray, rcond=None)\n",
    "    a = model[0][0]\n",
    "    b = model[1][0]\n",
    "\n",
    "    xp = range(150)\n",
    "    yp = [a*xi + b for xi in xp]\n",
    "\n",
    "    plt.plot(xp,yp, color = 'purple')\n",
    "    plt.title(f'Linear regression for {labels_attributes[attribute]}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    yr = [1/(a*xi+b) for xi in xp]\n",
    "\n",
    "    plt.scatter(x,y, marker = '.')\n",
    "    plt.plot(xp,yr, color = 'purple')\n",
    "    plt.title(f'Results with the original curve for {labels_attributes[attribute]}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    x_predicted = [(1/yi - b)/a for yi in peak_to_peak_var_real]\n",
    "\n",
    "    plt.scatter(x_predicted, peak_to_peak_var_real)\n",
    "    plt.title(f'Predictions for real data with {labels_attributes[attribute]}')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"The mean error for {labels_attributes[attribute]} is {np.mean(x_predicted)}\")\n",
    "\n",
    "    max_error = 1000\n",
    "    l = [1 for x in x_predicted if x < max_error ]\n",
    "    print(f\"There are {int(sum(l)*100/n_templates_real)}% of templates for which we predicted an error inferior to {max_error} um using the {labels_attributes[attribute]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The peak to peak variance varies between {min(peak_to_peak_var_real)} and {max(peak_to_peak_var_real)} for the real data, compared to {min([min(peak_to_peak_var[i]) for i in range (len(peak_to_peak_var))])} and {max([max(peak_to_peak_var[i]) for i in range (len(peak_to_peak_var))])} for artifical data\")\n",
    " \n",
    "print(f\"The norm varies between {min(frob_norms_real)} and {max(frob_norms_real)} for the real data, compared to {min([min(frob_norms[i]) for i in range (len(frob_norms))])} and {max([max(frob_norms[i]) for i in range (len(frob_norms))])} for artifical data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('si_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b50c9e5c20b80a7fea53278e7b85976e5483a9191b272239eb7a6e566d7885cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
